{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62348b02",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm\n",
    "from sklearn import ensemble\n",
    "from sklearn import dummy\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.fixes import loguniform\n",
    "import scipy\n",
    "import argparse\n",
    "\n",
    "from misc import save_model, load_model, regression_results, grid_search_cv, calculate_regression_metrics, supervised_learning_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da5fba",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Get the setting with different X_trains and X_tests\n",
    "train_options = [\"../Data/Training_Set_with_Drug_Embedding_Cell_Info.pkl\",\n",
    "                 \"../Data/Training_Set_with_Drug_MFP_Cell_Info.pkl\",\n",
    "                 \"..\"]\n",
    "test_options = [\"../Data/Test_Set_with_Drug_Embedding_Cell_Info.pkl\",\n",
    "                \"../Data/Test_Set_with_Drug_MFP_Cell_Info.pkl\",\n",
    "                \"..\"]\n",
    "data_type_options = [\"LS_Feat\",\"MFP_Feat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d99be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the options\n",
    "input_option = 1                                                  #Choose 0 for LS for Drug and LS for Cell Line , 1 for MFP for Drug and LS for Cell Line \n",
    "classification_task = False\n",
    "data_type = data_type_options[input_option]\n",
    "\n",
    "#Get the data for your choice: LS or MFP\n",
    "print(\"Loaded training file\")\n",
    "big_train_df = pd.read_pickle(train_options[input_option],compression=\"zip\")\n",
    "big_test_df = pd.read_pickle(test_options[input_option],compression=\"zip\")\n",
    "big_train_df = big_train_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "big_test_df = big_test_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "total_length = len(big_train_df.columns)\n",
    "if (input_option==0):\n",
    "    #Consider only those columns which have numeric values\n",
    "    metadata_X_train,X_train, Y_train = big_train_df.loc[:,[\"dbgap_rnaseq_sample\",\"inhibitor\"]], big_train_df.iloc[:,[1,4]+[*range(6,262,1)]+[*range(288,total_length,1)]], big_train_df[\"ic50\"].to_numpy().flatten()\n",
    "    metadata_X_test,X_test, Y_test = big_test_df.loc[:,[\"dbgap_rnaseq_sample\",\"inhibitor\"]], big_test_df.iloc[:,[1,4]+[*range(6,262,1)]+[*range(288,total_length,1)]], big_test_df[\"ic50\"].to_numpy().flatten()\n",
    "elif (input_option==1):\n",
    "    metadata_X_train,X_train, Y_train = big_train_df.loc[:,[\"dbgap_rnaseq_sample\",\"inhibitor\"]], big_train_df.iloc[:,[1,4]+[*range(6,1030,1)]+[*range(1056,total_length,1)]], big_train_df[\"ic50\"].to_numpy().flatten()\n",
    "    metadata_X_test,X_test, Y_test = big_test_df.loc[:,[\"dbgap_rnaseq_sample\",\"inhibitor\"]], big_test_df.iloc[:,[1,4]+[*range(6,1030,1)]+[*range(1056,total_length,1)]], big_test_df[\"ic50\"].to_numpy().flatten()\n",
    "\n",
    "#Keep only numeric training and test set and those which have no Nans\n",
    "X_train_numerics_only = X_train.select_dtypes(include=np.number)\n",
    "X_test_numerics_only = X_test[X_train_numerics_only.columns]\n",
    "print(\"Shape of training set after removing non-numeric cols\")\n",
    "print(X_train_numerics_only.shape)\n",
    "print(X_test_numerics_only.shape)\n",
    "\n",
    "\n",
    "nan_cols = [i for i in X_train_numerics_only.columns if X_train_numerics_only[i].isnull().any()]\n",
    "rev_X_train = X_train_numerics_only.drop(nan_cols,axis=1)\n",
    "rev_X_test = X_test_numerics_only.drop(nan_cols,axis=1)\n",
    "print(\"Shape of training set after removing cols with NaNs\")\n",
    "print(rev_X_train.shape)\n",
    "print(rev_X_test.shape)\n",
    "plt.hist(Y_train)\n",
    "plt.hist(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e592157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the LightGBM Regression model\n",
    "model = lightgbm.LGBMRegressor(boosting_type='gbdt',random_state=0, n_jobs=36, objective=\"regression\")\n",
    "\n",
    "# Grid parameters\n",
    "params_lgbm = {\n",
    "        \"n_estimators\": scipy.stats.randint(20, 500),\n",
    "        \"max_depth\": scipy.stats.randint(3, 9),\n",
    "        \"num_leaves\": [32, 64, 128, 256], \n",
    "        \"min_child_samples\": scipy.stats.randint(5, 20),\n",
    "        \"learning_rate\": loguniform(1e-4, 1e-1),\n",
    "        \"subsample\": loguniform(0.8, 1e0),\n",
    "        \"colsample_bytree\": [0.1, 0.3, 0.5, 0.7],\n",
    "        \"reg_alpha\": loguniform(1e-1, 1e1),\n",
    "        \"reg_lambda\": loguniform(1, 1e1)\n",
    "}   \n",
    "\n",
    "        \n",
    "#It will select 200 random combinations for the CV and do 5-fold CV for each combination\n",
    "n_iter = 100\n",
    "lgbm_gs=supervised_learning_steps(\"lgbm\",\"r2\",data_type,classification_task,model,params_lgbm,rev_X_train,Y_train,n_iter=n_iter,n_splits=5)\n",
    "        \n",
    "#Build the model and get 5-fold CV results    \n",
    "print(lgbm_gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the linear regression model on separate test set  \n",
    "lgbm_gs = load_model(\"lgbm_models/lgbm_\"+data_type+\"_regressor_gs.pk\")\n",
    "np.max(lgbm_gs.cv_results_[\"mean_test_score\"])\n",
    "lgbm_best = lgbm_gs.best_estimator_\n",
    "y_pred_lgbm=lgbm_best.predict(rev_X_test)\n",
    "test_metrics=calculate_regression_metrics(Y_test,y_pred_lgbm)\n",
    "print(test_metrics)\n",
    "\n",
    "#Write the prediction of LR model\n",
    "metadata_X_test['predictions']=y_pred_lgbm\n",
    "metadata_X_test['labels']=Y_test\n",
    "metadata_X_test.to_csv(\"../Results/LGBM_\"+data_type+\"_supervised_test_predictions.csv\",index=False,sep=\"\\t\")\n",
    "print(\"Finished writing predictions\")\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.style.use('classic')\n",
    "fig.set_size_inches(2.5,2.5)\n",
    "fig.set_dpi(300)\n",
    "fig.set_facecolor(\"white\")\n",
    "\n",
    "ax = sn.regplot(x=\"labels\", y=\"predictions\", data=metadata_X_test, scatter_kws={\"color\": \"lightblue\",'alpha':0.5}, \n",
    "                line_kws={\"color\": \"red\"})\n",
    "ax.axes.set_title(\"LGBM Predictions (MFP + Feat)\",fontsize=10)\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(0, 12)\n",
    "ax.set_xlabel(\"\",fontsize=10)\n",
    "ax.set_ylabel(\"\",fontsize=10)\n",
    "ax.tick_params(labelsize=10, color=\"black\")\n",
    "plt.text(2, 2, 'Pearson r =' +str(test_metrics[3]), fontsize = 10)\n",
    "plt.text(1, 1, 'MAE ='+str(test_metrics[0]),fontsize=10)\n",
    "outfilename = \"../Results/LGBM_\"+data_type+\"_supervised_test_prediction.pdf\"\n",
    "plt.savefig(outfilename, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec6c93",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#Get the most important variables and their feature importance scores\n",
    "lgbm_best = load_model(\"lgbm_models/lgbm_\"+data_type+\"_regressor_best_estimator.pk\")\n",
    "val, index = np.sort(lgbm_best.feature_importances_), np.argsort(lgbm_best.feature_importances_)\n",
    "fig = plt.figure()\n",
    "plt.style.use('classic')\n",
    "fig.set_size_inches(4,3)\n",
    "fig.set_dpi(300)\n",
    "fig.set_facecolor(\"white\")\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "plt.bar(rev_X_train.columns[index[-20:]],val[-20:])\n",
    "plt.xticks(rotation = 90) # Rotates X-Axis Ticks by 45-degrees\n",
    "\n",
    "ax.axes.set_title(\"Top LGBM VI (MFP + Feat)\",fontsize=9)\n",
    "ax.set_xlabel(\"Features\",fontsize=9)\n",
    "ax.set_ylabel(\"VI Value\",fontsize=9)\n",
    "ax.tick_params(labelsize=9)\n",
    "outputfile = \"../Results/LGBM_\"+data_type+\"_Coefficients.pdf\"\n",
    "plt.savefig(outputfile, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af3a44",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
