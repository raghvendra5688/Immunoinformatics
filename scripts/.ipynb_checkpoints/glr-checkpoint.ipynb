{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45381ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msn\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn import ensemble\n",
    "from sklearn import dummy\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.fixes import loguniform\n",
    "import scipy\n",
    "import argparse\n",
    "\n",
    "from misc import save_model, load_model, regression_results, grid_search_cv\n",
    "plt.rcParams[\"font.family\"] = \"Arial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27167813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regression_metrics(labels, predictions):\n",
    "    return round(metrics.mean_absolute_error(labels, predictions),3),\\\n",
    "            round(metrics.mean_squared_error(labels, predictions, squared=False),3),\\\n",
    "            round(np.power(scipy.stats.pearsonr(np.array(labels).flatten(),np.array(predictions.flatten()))[0],2),3),\\\n",
    "            round(scipy.stats.pearsonr(np.array(labels).flatten(),np.array(predictions.flatten()))[0],3),\\\n",
    "            round(scipy.stats.spearmanr(np.array(labels).flatten(),np.array(predictions.flatten()))[0],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad22e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_learning_steps(method, scoring, data_type, task, model, params, X_train, y_train, n_iter, n_splits = 5):\n",
    "    \n",
    "    gs = grid_search_cv(model, params, X_train, y_train, scoring=scoring, n_iter = n_iter, n_splits = n_splits)\n",
    "\n",
    "    y_pred = gs.predict(X_train)\n",
    "    #y_pred[y_pred < 0] = 0\n",
    "\n",
    "    if task:\n",
    "        results=calculate_classification_metrics(y_train, y_pred)\n",
    "        print(\"Acc: %.3f, F1: %.3f, AUC: %.3f, AUPR: %.3f\" % (results[0], results[1], results[2], results[3]))\n",
    "    else:\n",
    "        results=calculate_regression_metrics(y_train,y_pred)\n",
    "        print(\"MAE: %.3f, MSE: %.3f, R2: %.3f, Pearson R: %.3f, Spearman R: %.3f\" % (results[0], results[1], results[2], results[3], results[4]))\n",
    "   \n",
    "    print('Parameters')\n",
    "    print('----------')\n",
    "    for p,v in gs.best_estimator_.get_params().items():\n",
    "        print(p, \":\", v)\n",
    "    print('-' * 80)\n",
    "\n",
    "    if task:\n",
    "        save_model(gs, \"%s_models/%s_%s_classifier_gs.pk\" % (method,method,data_type))\n",
    "        save_model(gs.best_estimator_, \"%s_models/%s_%s_classifier_best_estimator.pk\" %(method,method,data_type))\n",
    "    else:\n",
    "        save_model(gs, \"%s_models/%s_%s_regressor_gs.pk\" % (method,method,data_type))\n",
    "        save_model(gs.best_estimator_, \"%s_models/%s_%s_regressor_best_estimator.pk\" %(method,method,data_type))\n",
    "    return(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the setting with different X_trains and X_tests\n",
    "train_options = [\"../Data/dose_response_with_full_data_inflammasome_with_ls_train.pkl\",\n",
    "                 \"../Data/dose_response_with_full_data_inflammasome_with_mfp_train.pkl\",\n",
    "                 \"..\"]\n",
    "test_options = [\"../Data/dose_response_with_full_data_inflammasome_with_ls_test.pkl\",\n",
    "                \"../Data/dose_response_with_full_data_inflammasome_with_mfp_test.pkl\",\n",
    "                \"..\"]\n",
    "data_type_options = [\"LS_LS\",\"MFP_LS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae7c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the options\n",
    "input_option = 0                                                  #Choose 0 for LS for Drug and LS for Cell Line , 1 for MFP for Drug and LS for Cell Line \n",
    "classification_task = False\n",
    "data_type = data_type_options[input_option]\n",
    "\n",
    "#Get the data for your choice: LS or MFP\n",
    "print(\"Loaded training file\")\n",
    "big_train_df = pd.read_pickle(train_options[input_option],compression=\"zip\")\n",
    "big_test_df = pd.read_pickle(test_options[input_option],compression=\"zip\")\n",
    "total_length = len(big_train_df.columns)\n",
    "metadata_X_train, X_train, Y_train = big_train_df.loc[:,['ARXSPAN_ID','DRUG_NAME']], big_train_df.iloc[:, range(16,total_length)], big_train_df[\"y_ic50\"].to_numpy().flatten()\n",
    "metadata_X_test, X_test, Y_test = big_test_df.loc[:,['ARXSPAN_ID','DRUG_NAME']], big_test_df.iloc[:,range(16,total_length)], big_test_df[\"y_ic50\"].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2288a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the Generalized Linear Regression model\n",
    "model = linear_model.ElasticNet()\n",
    "\n",
    "# Grid parameters\n",
    "params_glr = [\n",
    "    {\n",
    "        'l1_ratio' : [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], #scipy.stats.uniform.rvs(size=100, random_state=42),\n",
    "        'alpha' : [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], #scipy.stats.uniform.rvs(size=100, random_state=42),\n",
    "        'fit_intercept' : [True,False],\n",
    "        'max_iter': [5000,10000]\n",
    "    }\n",
    "]\n",
    "#It will select 1000 random combinations for the CV and do 5-fold CV for each combination\n",
    "n_iter = 100\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "X_train_copy = scaler.fit_transform(X_train)\n",
    "glr_gs=supervised_learning_steps(\"glr\",\"r2\",data_type,classification_task,model,params_glr,X_train_copy,Y_train,n_iter=n_iter,n_splits=5)\n",
    "        \n",
    "#Build the model and get 5-fold CV results    \n",
    "print(glr_gs.cv_results_)\n",
    "save_model(scaler, \"%s_models/%s_%s_scaling_gs.pk\" % (\"glr\",\"glr\",data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18804394",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#Test the linear regression model on separate test set   \n",
    "glr_gs = load_model(\"glr_models/glr_\"+data_type+\"_regressor_gs.pk\")\n",
    "scaler = load_model(\"glr_models/glr_\"+data_type+\"_scaling_gs.pk\")\n",
    "np.max(glr_gs.cv_results_[\"mean_test_score\"])\n",
    "glr_best = glr_gs.best_estimator_\n",
    "y_pred_glr=glr_best.predict(scaler.transform(X_test))\n",
    "test_metrics = calculate_regression_metrics(Y_test,y_pred_glr)\n",
    "print(test_metrics)\n",
    "\n",
    "#Write the prediction of LR model\n",
    "metadata_X_test['predictions']=y_pred_glr\n",
    "metadata_X_test['labels']=Y_test\n",
    "metadata_X_test.to_csv(\"../results/GLR_\"+data_type+\"_supervised_test_predictions.csv\",index=False)\n",
    "print(\"Finished writing predictions\")\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.style.use('classic')\n",
    "fig.set_size_inches(2.5,2.5)\n",
    "fig.set_dpi(300)\n",
    "fig.set_facecolor(\"white\")\n",
    "\n",
    "ax = sn.regplot(x=\"labels\", y=\"predictions\", data=metadata_X_test, scatter_kws={\"color\": \"lightblue\",'alpha':0.5}, \n",
    "                line_kws={\"color\": \"red\"})\n",
    "ax.axes.set_title(\"GLR Predictions (LS + LS)\",fontsize=10)\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-4, 4)\n",
    "ax.set_xlabel(\"\",fontsize=10)\n",
    "ax.set_ylabel(\"\",fontsize=10)\n",
    "ax.tick_params(labelsize=10, color=\"black\")\n",
    "plt.text(-4, 3, 'Pearson r =' +str(test_metrics[3]), fontsize = 10)\n",
    "plt.text(-4, 2, 'MAE ='+str(test_metrics[0]),fontsize=10)\n",
    "outfilename = \"../results/GLR_\"+data_type+\"_supervised_test_prediction.pdf\"\n",
    "plt.savefig(outfilename, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ead7b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#Get the top coefficients and matching column information\n",
    "glr_best = load_model(\"glr_models/glr_\"+data_type+\"_regressor_best_estimator.pk\")\n",
    "val, index = np.sort(np.abs(glr_best.coef_)), np.argsort(np.abs(glr_best.coef_))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.style.use('classic')\n",
    "fig.set_size_inches(4,3)\n",
    "fig.set_dpi(300)\n",
    "fig.set_facecolor(\"white\")\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "plt.bar(X_train.columns[index[-20:]],val[-20:])\n",
    "plt.xticks(rotation = 90) # Rotates X-Axis Ticks by 45-degrees\n",
    "ax.axes.set_title(\"Top GLR Coefficients (LS + LS)\",fontsize=10)\n",
    "ax.set_xlabel(\"Features\",fontsize=10)\n",
    "ax.set_ylabel(\"Coefficient Value\",fontsize=10)\n",
    "ax.tick_params(labelsize=10)\n",
    "outputfile = \"../results/GLR_\"+data_type+\"_Coefficients.pdf\"\n",
    "plt.savefig(outputfile, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa18ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
